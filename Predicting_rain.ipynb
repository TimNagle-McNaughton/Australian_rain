{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing, reading, and combining data\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# sklearn for classifiers and testing\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# data balancing\n",
    "import collections\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# figures and visualization\n",
    "import plotly.express as px\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# misc\n",
    "import time\n",
    "\n",
    "# maps\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008-12-06</td>\n",
       "      <td>Albury</td>\n",
       "      <td>14.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>56.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>1005.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.6</td>\n",
       "      <td>28.9</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008-12-07</td>\n",
       "      <td>Albury</td>\n",
       "      <td>14.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>50.0</td>\n",
       "      <td>SW</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1009.6</td>\n",
       "      <td>1008.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>24.6</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008-12-08</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.7</td>\n",
       "      <td>26.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>35.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1013.4</td>\n",
       "      <td>1010.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.3</td>\n",
       "      <td>25.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008-12-09</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.7</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNW</td>\n",
       "      <td>80.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1008.9</td>\n",
       "      <td>1003.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.3</td>\n",
       "      <td>30.2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008-12-10</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.1</td>\n",
       "      <td>30.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>28.0</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1005.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.1</td>\n",
       "      <td>28.2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "5  2008-12-06   Albury     14.6     29.7       0.2          NaN       NaN   \n",
       "6  2008-12-07   Albury     14.3     25.0       0.0          NaN       NaN   \n",
       "7  2008-12-08   Albury      7.7     26.7       0.0          NaN       NaN   \n",
       "8  2008-12-09   Albury      9.7     31.9       0.0          NaN       NaN   \n",
       "9  2008-12-10   Albury     13.1     30.1       1.4          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "5         WNW           56.0          W  ...        55.0         23.0   \n",
       "6           W           50.0         SW  ...        49.0         19.0   \n",
       "7           W           35.0        SSE  ...        48.0         19.0   \n",
       "8         NNW           80.0         SE  ...        42.0          9.0   \n",
       "9           W           28.0          S  ...        58.0         27.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "5       1009.2       1005.4       NaN       NaN     20.6     28.9         No   \n",
       "6       1009.6       1008.2       1.0       NaN     18.1     24.6         No   \n",
       "7       1013.4       1010.1       NaN       NaN     16.3     25.5         No   \n",
       "8       1008.9       1003.6       NaN       NaN     18.3     30.2         No   \n",
       "9       1007.0       1005.7       NaN       NaN     20.1     28.2        Yes   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "5            No  \n",
       "6            No  \n",
       "7            No  \n",
       "8           Yes  \n",
       "9            No  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get source data\n",
    "source_directory = \"E:\\Git_repos\\Australian_rain/\"\n",
    "source_table = \"E:\\Git_repos\\Australian_rain\\weatherAUS.csv\"\n",
    "shapefile = \"E:\\Git_repos\\Australian_rain\\states\\STE_2016_AUST.shp\"\n",
    "source_df = pd.read_csv(source_table)\n",
    "\n",
    "# explore dataset\n",
    "source_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data exploration\n",
    "\n",
    "This dataset contains a lot of really cool weather data that's fun to play around with in its own right. \n",
    "\n",
    "## Temperature data\n",
    "\n",
    "Let's examine some of the cyclical changes in temperature across Australia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set up time series figure\n",
    "fig, ax = plt.subplots(3, figsize=(12, 10));\n",
    "\n",
    "# make a function to generate some scatter plots\n",
    "def plot_minimum_temperature(station, index):\n",
    "    \n",
    "    # mask out a station of interest\n",
    "    station_id = station\n",
    "    station = source_df[source_df[\"Location\"] == station_id] \n",
    "    min_temp = station[\"MinTemp\"]\n",
    "\n",
    "    # plot the time series\n",
    "    ax[index].scatter(station[\"Date\"], min_temp, \n",
    "               c=station[\"MinTemp\"], marker=\".\", \n",
    "               cmap=\"coolwarm\");\n",
    "\n",
    "    # set titles, labels; remove axes\n",
    "    ax[index].set_title(\"Minimum daily temperature in {} over time\".format(station_id))\n",
    "    ax[index].set_ylabel(\"Temperature (C)\")\n",
    "    ax[index].get_xaxis().set_visible(False)\n",
    "    \n",
    "# plot some station data\n",
    "plot_minimum_temperature(\"Canberra\", 0)\n",
    "plot_minimum_temperature(\"Darwin\", 1)\n",
    "plot_minimum_temperature(\"Perth\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the temperatures in Darwin (nearer to the equator) are much hotter in the summer, and that the summers in Darwin are much longer. There also appears to be a nearly half-period shift between the temperatures in Canberra and Perth at the beginning of the dataset that eventually evens out by the 8th summer.\n",
    "\n",
    "### Wind data\n",
    "\n",
    "Since we have wind direction data it's only natural that we should make a rose diagram too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make out the station of interest\n",
    "wind_df = source_df[source_df[\"Location\"] == \"Canberra\"]\n",
    "\n",
    "# get the wind directions as frequencies\n",
    "wind_df = wind_df.groupby([\"WindGustDir\"]).size().reset_index(name=\"frequency\")\n",
    "\n",
    "# put the values in cardinal directions\n",
    "cardinal_order = [\"N\", \"NNE\", \"NE\", \"ENE\", \n",
    "                  \"E\", \"ESE\", \"SE\", \"SSE\", \n",
    "                  \"S\", \"SSW\", \"SW\", \"WSW\", \n",
    "                  \"W\", \"WNW\", \"NW\", \"NNW\"]\n",
    "\n",
    "# set the direction as the index\n",
    "wind_df = wind_df.set_index(wind_df[\"WindGustDir\"])\n",
    "\n",
    "# reorder it based on the correct direction\n",
    "wind_df = wind_df.reindex(cardinal_order)\n",
    "\n",
    "# generate a rose diagram\n",
    "fig = px.bar_polar(wind_df, r=\"frequency\", theta=\"WindGustDir\",\n",
    "                   color=\"frequency\", template=\"simple_white\",\n",
    "                   color_discrete_sequence= px.colors.sequential.haline)\n",
    "\n",
    "# add a title and legend\n",
    "fig.update_layout(\n",
    "    title='Wind Speed Distribution in Canberra, Australia',\n",
    "    font_size=12,\n",
    "    legend_font_size=12,\n",
    "    polar_angularaxis_rotation=90)\n",
    "  \n",
    "# show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be have a very strong NW signal, and a smaller E component.\n",
    "\n",
    "# Data preparation\n",
    "\n",
    "We need to massage our data for the algorithms, and also to enable later analysis. Here we'll assign each station to the state it's in, and change our categorical data with numerical substitutes. We also need to elimate records where NaN values cannot be determined, and fill NaN values where we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make territory dictionary (manually)\n",
    "territory_dict = {\"New South Wales\": ['Albury', 'BadgerysCreek', 'Cobar', 'CoffsHarbour', 'Moree', \n",
    "                          'Newcastle', 'NorahHead', 'NorfolkIsland', 'Penrith', 'Richmond', \n",
    "                          'Sydney', 'SydneyAirport', 'WaggaWagga', 'Williamtown', 'Wollongong'],\n",
    "                  \"Victoria\": ['Ballarat', 'Bendigo', 'Dartmoor', 'Sale', 'MelbourneAirport', 'Melbourne','Mildura',\n",
    "                          'Nhil', 'Portland', 'Watsonia'],\n",
    "                  \"Queensland\": ['Brisbane', 'Cairns', 'GoldCoast', 'Townsville'],\n",
    "                  \"South Australia\": ['Adelaide', 'MountGambier', 'Nuriootpa', 'Woomera'],\n",
    "                  \"Western Australia\": ['Albany', 'Witchcliffe', 'PearceRAAF', 'PerthAirport', 'Perth', 'SalmonGums'\n",
    "                          'Walpole'],\n",
    "                  \"Tasmania\": ['Hobart', 'Launceston'],\n",
    "                  \"Northern Territories\": ['AliceSprings', 'Darwin', 'Katherine', 'Uluru'],\n",
    "                  \"Australian Capital Territory\": ['Canberra', 'Tuggeranong', 'Mount Ginini'], }\n",
    "\n",
    "# replace categorical values\n",
    "cardinal_dict = {\"N\": 0, \"NNE\": 1, \"NE\": 2, \"ENE\": 3,\n",
    "                 \"E\": 4, \"ESE\": 5, \"SE\": 6, \"SSE\": 7,\n",
    "                 \"S\": 8, \"SSW\": 9, \"SW\": 10, \"WSW\": 11,\n",
    "                 \"W\": 12, \"WNW\": 13, \"NW\": 14, \"NNW\": 15}\n",
    "\n",
    "\n",
    "# substitute the cardinal directions wherever they occur\n",
    "categorical_replacements = {\"WindGustDir\": cardinal_dict,\n",
    "                            \"WindDir9am\": cardinal_dict,\n",
    "                            \"WindDir3pm\": cardinal_dict,\n",
    "                            \"RainToday\": {\"No\":0, \"Yes\": 1},\n",
    "                            \"RainTomorrow\": {\"No\":0, \"Yes\": 1}}\n",
    "\n",
    "# convert the categorical data\n",
    "source_df = source_df.replace(categorical_replacements)\n",
    "\n",
    "# drop columns that are mostly NaN right away.\n",
    "source_df.drop(columns=['Evaporation', 'Sunshine', \"Cloud9am\", \"Cloud3pm\"])\n",
    "\n",
    "# drop any row with a NaN\n",
    "source_df = source_df.dropna(axis=0)\n",
    "\n",
    "# check the header now\n",
    "source_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for correlated values\n",
    "\n",
    "Since we're going to be training some models on these data, we should make sure that we don't have any proxy features that will let the model cheat. Here we'll generate a correlation matrix between all the features. We're most concerned about high correlations between \"Rainfall\" (measured in mm), \"RainToday\" (binary yes/no or really 1/0), and \"RainTomorrow\" (also binary 1/0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set up the correlation figure\n",
    "fig, ax = plt.subplots(1, figsize=(18, 12));\n",
    "\n",
    "correlation_df = source_df\n",
    "\n",
    "ax.set_title(\"All variable cross-correlations\", fontdict={\"fontsize\": \"18\", \"fontweight\": \"3\"}, \n",
    "             loc='center', pad=None)\n",
    "\n",
    "corrMatrix = correlation_df.corr()\n",
    "sn.heatmap(corrMatrix, annot=True ,ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Rainfall\" and \"RainToday\" are correlated (0.5) which is no suprise. We will exlude \"Rainfall\" when we try to predict \"RainToday\". Otherwise, the correlations between the other features and and \"RainToday\" and \"RainTomorrow\" are very low, which is excellent. This will allow us to demonstrate the efficacy of a complex model like a random forest. \n",
    "\n",
    "Next, we'll set up the features and targets for predicting rain tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of features, split into independent and dependent\n",
    "tomorrow_feature_list = ['MinTemp', 'MaxTemp', \n",
    "                         'Rainfall', 'WindGustDir', \n",
    "                         'WindGustSpeed', 'WindDir9am', \n",
    "                         'WindDir3pm', 'WindSpeed9am', \n",
    "                         'WindSpeed3pm', 'Humidity9am', \n",
    "                         'Humidity3pm', 'Pressure9am', \n",
    "                         'Pressure3pm', 'Temp9am', \n",
    "                         'Temp3pm', 'RainToday']\n",
    "tomorrow_target_list = ['RainTomorrow']\n",
    "\n",
    "# split\n",
    "features = source_df.loc[:, tomorrow_feature_list]\n",
    "target = source_df.loc[:, tomorrow_target_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rain in Australia is pretty rare, so let's check to see if our \"RainTomorrow\" classes are imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the balance of the data\n",
    "count_no_rain = len(target[target[\"RainTomorrow\"] == 0])\n",
    "count_rain = len(target[target[\"RainTomorrow\"] == 1])\n",
    "balance = round(count_rain/count_no_rain, 1)\n",
    "print(\"The starting balance is: ~{}% 'rain'.\".format(100*balance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some data and see which values correspond to rain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set up a figure\n",
    "fig, ax = plt.subplots(1, figsize=(8, 8));\n",
    "\n",
    "# set the title\n",
    "ax.set_title(\"Color coding for rain\", fontdict={\"fontsize\": \"18\", \"fontweight\": \"3\"}, \n",
    "             loc='center', pad=None)\n",
    "\n",
    "# plot two variables and color code by our target classes\n",
    "ax.scatter(features[\"Humidity3pm\"], features[\"Pressure3pm\"], \n",
    "            c=target[\"RainTomorrow\"], alpha=0.1, marker='.', cmap='RdYlGn')\n",
    "\n",
    "# label the axes\n",
    "ax.set_ylabel(\"Humidity at 3pm (%)\")\n",
    "ax.set_xlabel(\"Atmospheric pressure at 3pm (milibar)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are way more red values than green values so our data are imbalanced. We can fix that by generating sythetic samples of \"rain\" in \"RainTomorrow\" to even things out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance the data via SMOTE\n",
    "oversample = SMOTE()\n",
    "features_res, target_res = oversample.fit_resample(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare that same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a figure\n",
    "fig, ax = plt.subplots(1, figsize=(8, 8));\n",
    "\n",
    "# set the title\n",
    "ax.set_title(\"Color coding for rain\", fontdict={\"fontsize\": \"18\", \"fontweight\": \"3\"}, \n",
    "             loc='center', pad=None)\n",
    "\n",
    "# plot two variables and color code by our target classes\n",
    "ax.scatter(features_res[\"Humidity3pm\"], features_res[\"Pressure3pm\"], \n",
    "            c=target_res[\"RainTomorrow\"], alpha=0.1, marker='.', cmap='RdYlGn')\n",
    "\n",
    "# label the axes\n",
    "ax.set_ylabel(\"Humidity at 3pm (%)\")\n",
    "ax.set_xlabel(\"Atmospheric pressure at 3pm (milibar)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the target classes are much more balanced now.\n",
    "\n",
    "We next need to scale all the features for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize all the features\n",
    "features = StandardScaler().fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll reserve 20% of the data as our test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(features_res, \n",
    "                                                                          target_res, \n",
    "                                                                          test_size=0.2, \n",
    "                                                                          random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize our models we'll do a cross-validated grid search. To make things easier, we'll make a function to return the optimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that performs a grid search\n",
    "def rain_grid_search(estimator, parameter_grid, train_X, train_y):\n",
    "  \n",
    "    # mark the start of the tuning process  \n",
    "    start_time = time.time()\n",
    "\n",
    "    # initalize the grid search\n",
    "    grid_search = GridSearchCV(estimator, parameter_grid, n_jobs=-1)\n",
    "\n",
    "    # apply the grid search to the training data\n",
    "    grid_search_application = grid_search.fit(train_X, train_y)\n",
    "\n",
    "    # mark the end of the tuning process\n",
    "    end_time = time.time()\n",
    "\n",
    "    # print the elapsed time\n",
    "    print(\"Grid search time: {}\".format(round(end_time - start_time, 3)))\n",
    "\n",
    "    # return the best parameters\n",
    "    return(grid_search_application.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now optimize our classifier's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune decision tree's hyperparameters\n",
    "parameter_grid =  {'criterion': [\"gini\", \"entropy\"],\n",
    "                   'splitter': [\"best\", \"random\"],\n",
    "                   'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "                   'max_depth': [5, 10, 20, 40, 100, 200],\n",
    "                   'min_samples_leaf': [1, 2, 4, 6, 8, 10, 100]}\n",
    "\n",
    "dt_parameters = rain_grid_search(DecisionTreeClassifier(), \n",
    "                                 parameter_grid, \n",
    "                                 feature_train, \n",
    "                                 target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll write a function to apply our decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to apply a decision tree\n",
    "def apply_decision_tree(train_X, train_y, test_X, test_y):\n",
    "    \n",
    "    # mark the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # initialize the dt model\n",
    "    dt_model = DecisionTreeClassifier(criterion=dt_parameters['criterion'],\n",
    "                                      splitter=dt_parameters['splitter'],\n",
    "                                      max_depth=dt_parameters['max_depth'],\n",
    "                                      min_samples_leaf=dt_parameters['min_samples_leaf'],\n",
    "                                      max_features=dt_parameters['max_features'])\n",
    "\n",
    "    # fit the model to the training data\n",
    "    dt_model.fit(train_X, train_y)\n",
    "\n",
    "    # apply the model to the test data\n",
    "    dt_model_predict = dt_model.predict(test_X)\n",
    "\n",
    "    # mark the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # save the time elapsed\n",
    "    dt_model_time = round(end_time - start_time, 3)\n",
    "\n",
    "    # get the results\n",
    "    dt_results = classification_report(test_y, dt_model_predict)\n",
    "    dt_dict_results = classification_report(test_y, dt_model_predict, output_dict=True)\n",
    "    \n",
    "    # print the results and parameters\n",
    "    print(\"Time to apply the classifier: \" + str(dt_model_time) + \"s.\")\n",
    "    \n",
    "    return dt_dict_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by testing a decision tree on the whole of Australia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply a decision tree to the whole country\n",
    "results = apply_decision_tree(feature_train, target_train, feature_test, target_test);\n",
    "\n",
    "# print the accuracy\n",
    "print(\"Overall accuracy: {}%\".format(round(100*results[\"accuracy\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overall accuracy of ~85% is pretty good across the whole country, but let's see if we can't do better if we split the country up by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make a simple dictionary to store results\n",
    "tomorrow_accuracy_list = []\n",
    "\n",
    "# loop through each state and apply the same functions as above\n",
    "for state in territory_dict:\n",
    "    \n",
    "    print(\"State: \" + state)\n",
    "    \n",
    "    # mask stations not in that state\n",
    "    state_df = source_df[source_df[\"Location\"].isin(territory_dict[state])]\n",
    "    \n",
    "    # split into features and targets\n",
    "    state_features = state_df.loc[:, tomorrow_feature_list].values\n",
    "    state_target = state_df.loc[:, tomorrow_target_list].values\n",
    "    \n",
    "    # standardize the features by state\n",
    "    state_features = StandardScaler().fit_transform(state_features)\n",
    "    \n",
    "    # balance the state samples\n",
    "    state_features_res, state_target_res = oversample.fit_resample(state_features, state_target)\n",
    "    \n",
    "    # train/test split by state\n",
    "    state_feature_train, state_feature_test, state_target_train, state_target_test = train_test_split(state_features_res, \n",
    "                                                                                                      state_target_res, \n",
    "                                                                                                      test_size=0.2, \n",
    "                                                                                                      random_state=42)\n",
    "    \n",
    "    # tune the decision tree\n",
    "    dt_parameters = rain_grid_search(DecisionTreeClassifier(), \n",
    "                                     parameter_grid, \n",
    "                                     state_feature_train, \n",
    "                                     state_target_train)\n",
    "    \n",
    "    # apply the decision tree\n",
    "    results = apply_decision_tree(state_feature_train, \n",
    "                                  state_target_train, \n",
    "                                  state_feature_test, \n",
    "                                  state_target_test)\n",
    "\n",
    "    \n",
    "    tomorrow_accuracy_list.append(round(results['accuracy'], 3))\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is essentially spatial data, so let's plot it as a map. First we need to get some geographic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the shapefile\n",
    "Australia = gpd.read_file(shapefile)\n",
    "\n",
    "# drop the 'other' states\n",
    "Australia.drop(Australia.tail(1).index,inplace=True)\n",
    "\n",
    "# add the accuracy data as a new column\n",
    "Australia[\"Tomorrow Accuracy\"] = tomorrow_accuracy_list\n",
    "\n",
    "# generate centroids for each state\n",
    "Australia['coords'] = Australia['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "Australia['coords'] = [coords[0] for coords in Australia['coords']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the overall accuracy by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set up the map figure\n",
    "fig, ax = plt.subplots(1, figsize=(10, 6));\n",
    "\n",
    "# set the title\n",
    "ax.set_title(\"Decision tree next-day rainfall prediction accuracy\", fontdict={\"fontsize\": \"18\", \n",
    "                                                                              \"fontweight\": \"3\"})\n",
    "\n",
    "# plot the accuracy column\n",
    "Australia.plot(column=\"Tomorrow Accuracy\", linewidth=0.8, ax=ax, edgecolor='0', cmap='RdYlGn');\n",
    "\n",
    "# annotate the states with their scores\n",
    "for idx, row in Australia.iterrows():\n",
    "    ax.text(row.coords[0], row.coords[1], \n",
    "            s=row[\"Tomorrow Accuracy\"], \n",
    "            horizontalalignment='center', \n",
    "            bbox={'facecolor': 'white', 'alpha':0.8, 'pad': 2, 'edgecolor':'none'})\n",
    "\n",
    "# set up the color bar\n",
    "sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(vmin=75, vmax=100))\n",
    "\n",
    "# make an empty array for the data range\n",
    "sm._A = []\n",
    "\n",
    "# plot the bar\n",
    "bar = fig.colorbar(sm)\n",
    "\n",
    "# remove axes from map\n",
    "ax.axis('off')\n",
    "\n",
    "plt.savefig(source_directory + \"/Figures/Next-day_accuracy.png\", dpi=300, transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the list\n",
    "today_feature_list = tomorrow_feature_list\n",
    "\n",
    "# remove the target from the features\n",
    "if 'RainToday' in today_feature_list:\n",
    "    today_feature_list.remove('RainToday')\n",
    "    \n",
    "# remove an obvious proxy too\n",
    "if 'Rainfall' in today_feature_list:\n",
    "    today_feature_list.remove('Rainfall')\n",
    "    \n",
    "# set the new target\n",
    "today_target_list = ['RainToday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a simple dictionary to store results\n",
    "today_accuracy_list = []\n",
    "\n",
    "# loop through each state and apply the same functions as above\n",
    "for state in territory_dict:\n",
    "    \n",
    "    print(\"State: \" + state)\n",
    "    \n",
    "    # mask stations not in that state\n",
    "    state_df = source_df[source_df[\"Location\"].isin(territory_dict[state])]\n",
    "    \n",
    "    # split into features and targets\n",
    "    state_features = state_df.loc[:, today_feature_list].values\n",
    "    state_target = state_df.loc[:, today_target_list].values\n",
    "    \n",
    "    # standardize the features by state\n",
    "    state_features = StandardScaler().fit_transform(state_features)\n",
    "    \n",
    "    # balance the state samples\n",
    "    state_features_res, state_target_res = oversample.fit_resample(state_features, state_target)\n",
    "    \n",
    "    # train/test split by state\n",
    "    state_feature_train, state_feature_test, state_target_train, state_target_test = train_test_split(state_features_res, \n",
    "                                                                                                      state_target_res, \n",
    "                                                                                                      test_size=0.2, \n",
    "                                                                                                      random_state=42)\n",
    "    \n",
    "    # tune the decision tree\n",
    "    dt_parameters = rain_grid_search(DecisionTreeClassifier(), \n",
    "                                     parameter_grid, \n",
    "                                     state_feature_train, \n",
    "                                     state_target_train)\n",
    "    \n",
    "    # apply the decision tree\n",
    "    results = apply_decision_tree(state_feature_train, \n",
    "                                  state_target_train, \n",
    "                                  state_feature_test, \n",
    "                                  state_target_test)\n",
    "\n",
    "    \n",
    "    today_accuracy_list.append(round(results['accuracy'],3))\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the today accuracy data as a new column\n",
    "Australia[\"Today Accuracy\"] = today_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the today map figure\n",
    "fig, ax = plt.subplots(1, figsize=(10, 6));\n",
    "\n",
    "# set the title\n",
    "ax.set_title(\"Decision tree rainfall prediction accuracy\", fontdict={\"fontsize\": \"18\", \n",
    "                                                                     \"fontweight\": \"3\"})\n",
    "\n",
    "# plot the accuracy column\n",
    "Australia.plot(column=\"Today Accuracy\", linewidth=0.8, ax=ax, edgecolor='0', cmap='RdYlGn');\n",
    "\n",
    "# loop through the geodataframe\n",
    "for idx, row in Australia.iterrows():\n",
    "    \n",
    "    # annotate the states with their scores\n",
    "    ax.text(row.coords[0], row.coords[1], \n",
    "            s=row[\"Today Accuracy\"], \n",
    "            horizontalalignment='center', \n",
    "            bbox={'facecolor': 'white', 'alpha':0.8, 'pad': 2, 'edgecolor':'none'})\n",
    "\n",
    "# set up the color bar\n",
    "sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(vmin=75, vmax=100))\n",
    "\n",
    "# make an empty array for the data range\n",
    "sm._A = []\n",
    "\n",
    "# plot the bar\n",
    "bar = fig.colorbar(sm)\n",
    "\n",
    "# remove axes from map\n",
    "ax.axis('off')\n",
    "\n",
    "plt.savefig(source_directory + \"/Figures/Same-day_accuracy.png\", dpi=300, transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Australia.head(9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
